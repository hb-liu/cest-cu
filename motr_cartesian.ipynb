{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T07:18:19.687506Z",
     "iopub.status.busy": "2024-07-31T07:18:19.687303Z",
     "iopub.status.idle": "2024-07-31T07:18:20.489983Z",
     "shell.execute_reply": "2024-07-31T07:18:20.489584Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import tables\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import cat\n",
    "from torch.fft import *\n",
    "from scipy.io import savemat\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T07:18:20.491458Z",
     "iopub.status.busy": "2024-07-31T07:18:20.491301Z",
     "iopub.status.idle": "2024-07-31T07:18:20.494960Z",
     "shell.execute_reply": "2024-07-31T07:18:20.494688Z"
    }
   },
   "outputs": [],
   "source": [
    "# load complementary undersampling cartesian trajectories\n",
    "\n",
    "datapath = 'data/bruker/5_cu_96x96_cest'\n",
    "\n",
    "nCU = tables.open_file(os.path.join(datapath,'MTCUNOffs.mat')).root.MTCUNOffs\n",
    "nCU = int(np.array(nCU).squeeze())\n",
    "imsize = [96,96]\n",
    "\n",
    "PEs = tables.open_file(os.path.join(datapath,'MT_spatial_phase_1.mat')).root.MT_spatial_phase_1\n",
    "PEs = np.array(PEs) * imsize[1] / 2 + imsize[1] / 2\n",
    "PEs = np.round(PEs).astype(np.int32).squeeze()\n",
    "\n",
    "PEs = PEs.tolist()\n",
    "PEs = np.array([PEs[-1]]+PEs[0:-1])\n",
    "PEs = np.split(PEs, nCU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T07:18:20.496037Z",
     "iopub.status.busy": "2024-07-31T07:18:20.495916Z",
     "iopub.status.idle": "2024-07-31T07:18:20.497699Z",
     "shell.execute_reply": "2024-07-31T07:18:20.497538Z"
    }
   },
   "outputs": [],
   "source": [
    "# define utility functions\n",
    "\n",
    "def ifft2c(k):\n",
    "    return ifftshift(ifft2(fftshift(k)))\n",
    "\n",
    "def fft2c(x):\n",
    "    return fftshift(fft2(ifftshift(x)))\n",
    "\n",
    "def view_as_complex(x):\n",
    "    x = torch.chunk(x, chunks=2, dim=1)\n",
    "    x = x[0] + 1j * x[1]\n",
    "    return x\n",
    "\n",
    "def view_as_real(x):\n",
    "    x = torch.cat([x.real, x.imag], dim=1).float()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T07:18:20.498731Z",
     "iopub.status.busy": "2024-07-31T07:18:20.498630Z",
     "iopub.status.idle": "2024-07-31T07:18:20.501883Z",
     "shell.execute_reply": "2024-07-31T07:18:20.501723Z"
    }
   },
   "outputs": [],
   "source": [
    "# define dataset\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, datapath, nCU, PEs):\n",
    "        self.PEs = PEs\n",
    "        self.nCU  = nCU\n",
    "        names = set([os.path.splitext(name)[0] for name in os.listdir(datapath)])\n",
    "        self.data_dict = {}\n",
    "        for name in names:\n",
    "            self.data_dict[name] = {}\n",
    "            data = torch.from_numpy(np.load(os.path.join(datapath, f'{name}.npy')))\n",
    "            with open(os.path.join(datapath, f'{name}.pkl'), 'rb') as f:\n",
    "                offsets = pickle.load(f)\n",
    "            # sort out M0 images and functional images\n",
    "            m0imgs, funimgs = [], []\n",
    "            for offset, img in zip(offsets, data):\n",
    "                if int(offset[0]) >= 100:\n",
    "                    img = ifft2c(img)\n",
    "                    m0imgs.append(img)\n",
    "                else:\n",
    "                    funimgs.append(img)\n",
    "            self.data_dict[name]['m0'] = torch.mean(torch.stack(m0imgs), 0, keepdim=True)\n",
    "            self.data_dict[name]['fun'] = torch.stack(funimgs)\n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for key in self.data_dict.keys():\n",
    "            count += len(self.data_dict[key]['fun']) - self.nCU + 1\n",
    "        return count\n",
    "    def __getitem__(self, index):\n",
    "        # index corresponds which sample\n",
    "        for key in self.data_dict.keys():\n",
    "            nseq = len(self.data_dict[key]['fun']) - self.nCU + 1\n",
    "            if index - nseq < 0:\n",
    "                break\n",
    "            index -= nseq\n",
    "        # fetch data\n",
    "        m0 = self.data_dict[key]['m0']\n",
    "        kf = self.data_dict[key]['fun'][index:index+self.nCU]\n",
    "        ku = []\n",
    "        for i in range(nCU):\n",
    "            mask = torch.zeros_like(kf[i],dtype=bool)\n",
    "            mask[:,PEs[i]] = 1\n",
    "            ku.append(kf[i] * mask)\n",
    "        ku = torch.stack(ku)\n",
    "        xf = ifft2c(kf)\n",
    "        xu = ifft2c(ku)\n",
    "        return xu, xf, ku, m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T07:18:20.502946Z",
     "iopub.status.busy": "2024-07-31T07:18:20.502868Z",
     "iopub.status.idle": "2024-07-31T07:18:20.508396Z",
     "shell.execute_reply": "2024-07-31T07:18:20.508238Z"
    }
   },
   "outputs": [],
   "source": [
    "# define variation network\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, dim_head=64, heads=8):\n",
    "        super().__init__()\n",
    "        self.num_heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.to_q = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.to_k = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.to_v = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.rescale = nn.Parameter(torch.ones(heads, 1, 1))\n",
    "        self.proj = nn.Linear(dim_head * heads, dim, bias=True)\n",
    "        self.pos_emb = nn.Conv2d(dim, dim, 3, 1, 1, bias=False, groups=dim)\n",
    "        self.dim = dim\n",
    "    def forward(self, x_in):\n",
    "        b, c, h, w = x_in.shape\n",
    "        x = x_in.permute(0, 2, 3, 1).reshape(b,h*w,c)\n",
    "        # b, hw, hd\n",
    "        q_inp = self.to_q(x)\n",
    "        k_inp = self.to_k(x)\n",
    "        v_inp = self.to_v(x)\n",
    "        # b, h, hw, d\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.num_heads), (q_inp, k_inp, v_inp))\n",
    "        # b, h, d, hw\n",
    "        q = q.transpose(-2, -1)\n",
    "        k = k.transpose(-2, -1)\n",
    "        v = v.transpose(-2, -1)\n",
    "        q = F.normalize(q, dim=-1, p=2)\n",
    "        k = F.normalize(k, dim=-1, p=2)\n",
    "        # attn: b, h, d, d\n",
    "        attn = (k @ q.transpose(-2, -1))\n",
    "        attn = attn * self.rescale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        # x: b, h, d, hw\n",
    "        x = attn @ v\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.reshape(b, h * w, self.num_heads * self.dim_head)\n",
    "        # out: b, c, h, w\n",
    "        out_c = self.proj(x).view(b, h, w, c).permute(0, 3, 1, 2)\n",
    "        out_p = self.pos_emb(x_in)\n",
    "        out = out_c + out_p\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mult=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim * mult, 1, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dim * mult, dim * mult, 3, 1, 1, bias=False, groups=dim * mult),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dim * mult, dim, 1, 1, bias=False),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, idim, hdim, odim, dim_head=64, heads=8, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.convin = nn.Sequential(nn.Conv2d(idim, hdim, 3, 1, 1, bias=False), nn.GELU())\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(\n",
    "                nn.ModuleList([\n",
    "                    Attention(dim=hdim, dim_head=dim_head, heads=heads),\n",
    "                    FeedForward(dim=hdim)\n",
    "                ])\n",
    "            )\n",
    "        self.convout = nn.Conv2d(hdim, odim, 1, 1, 0)\n",
    "    def forward(self, x, m0):\n",
    "        m0 = view_as_real(m0)\n",
    "        x  = view_as_real(x)\n",
    "        x  = torch.cat([x,m0],1)\n",
    "        x  = self.convin(x)\n",
    "        for (attn, ff) in self.blocks:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        out = self.convout(x)\n",
    "        out = view_as_complex(out)\n",
    "        return out\n",
    "\n",
    "class vn(nn.Module):\n",
    "    def __init__(self, idim, hdim, odim, niter):\n",
    "        super(vn, self).__init__()\n",
    "        self.iters = nn.ModuleList()\n",
    "        for i in range(niter):\n",
    "            self.iters.append(Transformer(idim, hdim, odim))\n",
    "    def forward(self, x, ku, m0):\n",
    "        for layer in self.iters:\n",
    "            x = x + layer(x,m0)\n",
    "            # data consistency\n",
    "            kx = fft2c(x) * (ku == 0) + ku\n",
    "            x = ifft2c(kx)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T07:18:20.509370Z",
     "iopub.status.busy": "2024-07-31T07:18:20.509244Z",
     "iopub.status.idle": "2024-07-31T07:18:20.510831Z",
     "shell.execute_reply": "2024-07-31T07:18:20.510677Z"
    }
   },
   "outputs": [],
   "source": [
    "# define learning rate scheduler\n",
    "\n",
    "class PolyScheduler(LambdaLR):\n",
    "    def __init__(self, optimizer, t_total, exponent=0.9, last_epoch=-1):\n",
    "        self.t_total = t_total\n",
    "        self.exponent = exponent\n",
    "        super(PolyScheduler, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        return (1 - step / self.t_total)**self.exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T07:18:20.511697Z",
     "iopub.status.busy": "2024-07-31T07:18:20.511635Z",
     "iopub.status.idle": "2024-07-31T11:30:29.160921Z",
     "shell.execute_reply": "2024-07-31T11:30:29.160506Z"
    }
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "\n",
    "trainset = dataset('data/processed/trains', nCU, PEs)\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "# take a snapshot of xu, xf, and m0\n",
    "xu, xf, ku, m0 = trainset.__getitem__(0)\n",
    "print(xu.shape, xf.shape, ku.shape, m0.shape)\n",
    "for i in range(nCU):\n",
    "    plt.subplot(2, nCU, i+1)\n",
    "    plt.imshow(abs(xu)[i].cpu().numpy(), cmap='gray')\n",
    "    plt.subplot(2, nCU, nCU+i+1)\n",
    "    plt.imshow(abs(xf)[i].cpu().numpy(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# hyper-parameters\n",
    "lr, weight_decay, epochs = 1e-4, 1e-4, 60\n",
    "\n",
    "net = vn(idim=2*(1+nCU), hdim=16, odim=2*nCU, niter=6).cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = PolyScheduler(optimizer, t_total=epochs)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "iter = 0\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(epochs):\n",
    "    for xu, xf, ku, m0 in trainloader:\n",
    "        xu, xf, ku, m0 = xu.cuda(), xf.cuda(), ku.cuda(), m0.cuda()\n",
    "        xr = net(xu, ku, m0)\n",
    "        loss = criterion(xr, xf)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        writer.add_scalar('Loss/train', loss.item(), iter)\n",
    "        iter = iter + 1\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(net.state_dict(), 'variables/motr_cartesian/motr.pth')\n",
    "\n",
    "# take a snapshot of xr and xf\n",
    "for i in range(nCU):\n",
    "    plt.subplot(2, nCU, i+1)\n",
    "    plt.imshow(abs(xr)[0][i].detach().cpu().numpy())\n",
    "    plt.subplot(2, nCU, nCU+i+1)\n",
    "    plt.imshow(abs(xf)[0][i].detach().cpu().numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
