{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:38.368698Z",
     "iopub.status.busy": "2024-09-08T11:56:38.368633Z",
     "iopub.status.idle": "2024-09-08T11:56:40.121001Z",
     "shell.execute_reply": "2024-09-08T11:56:40.120686Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import tables\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import cat\n",
    "from tqdm import tqdm\n",
    "from torch.fft import *\n",
    "import torchkbnufft as tkbn\n",
    "from einops import rearrange\n",
    "from scipy.io import savemat\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:40.122447Z",
     "iopub.status.busy": "2024-09-08T11:56:40.122281Z",
     "iopub.status.idle": "2024-09-08T11:56:40.129280Z",
     "shell.execute_reply": "2024-09-08T11:56:40.128788Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup seed\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "setup_seed(12345)\n",
    "# set num threads\n",
    "torch.set_num_threads(6)    # too many threads slows training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:40.131053Z",
     "iopub.status.busy": "2024-09-08T11:56:40.130656Z",
     "iopub.status.idle": "2024-09-08T11:56:40.582952Z",
     "shell.execute_reply": "2024-09-08T11:56:40.582595Z"
    }
   },
   "outputs": [],
   "source": [
    "# load spiral trajectory - see gen_spiral_grad.m\n",
    "\n",
    "imsize = [96, 96]\n",
    "\n",
    "trajpath = 'data/spiral/3x'\n",
    "traj = tables.open_file(os.path.join(trajpath, 'traj.mat')).root.traj\n",
    "\n",
    "nimgs = traj.real.shape[0]\n",
    "\n",
    "ktrajs = []\n",
    "for i in range(nimgs):\n",
    "    kx, ky = traj.real[i], traj.imag[i]\n",
    "    kx = torch.from_numpy(kx)\n",
    "    ky = torch.from_numpy(ky)\n",
    "    kmax = torch.sqrt(kx**2+ky**2).max()\n",
    "    kx, ky = kx / kmax * torch.pi, ky / kmax * torch.pi # normalize to (-pi, pi) for torchbknufft\n",
    "    ktrajs.append(torch.stack([kx,ky]))\n",
    "    plt.plot(kx, ky)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:40.584797Z",
     "iopub.status.busy": "2024-09-08T11:56:40.584718Z",
     "iopub.status.idle": "2024-09-08T11:56:40.587193Z",
     "shell.execute_reply": "2024-09-08T11:56:40.586855Z"
    }
   },
   "outputs": [],
   "source": [
    "# define utility functions\n",
    "\n",
    "def ifft2c(k):\n",
    "    return ifftshift(ifft2(fftshift(k)))\n",
    "\n",
    "def fft2c(x):\n",
    "    return fftshift(fft2(ifftshift(x)))\n",
    "\n",
    "def view_as_complex(x):\n",
    "    x = torch.chunk(x, chunks=2, dim=1)\n",
    "    x = x[0] + 1j * x[1]\n",
    "    return x\n",
    "\n",
    "def view_as_real(x):\n",
    "    x = torch.cat([x.real, x.imag], dim=1).float()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:40.588189Z",
     "iopub.status.busy": "2024-09-08T11:56:40.588110Z",
     "iopub.status.idle": "2024-09-08T11:56:40.592389Z",
     "shell.execute_reply": "2024-09-08T11:56:40.592233Z"
    }
   },
   "outputs": [],
   "source": [
    "# define dataset\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, datapath, ktrajs, imsize, nimgs):\n",
    "        self.nimgs  = nimgs\n",
    "        self.imsize = imsize\n",
    "        self.ktrajs = torch.stack(ktrajs).cuda()\n",
    "        # contruct nufft object\n",
    "        self.nufft = tkbn.KbNufft(imsize).cuda()\n",
    "        self.adj = tkbn.KbNufftAdjoint(imsize).cuda()\n",
    "        self.dcf = tkbn.calc_density_compensation_function(self.ktrajs, imsize).cuda()\n",
    "        # load all data\n",
    "        names = set([os.path.splitext(name)[0] for name in os.listdir(datapath)])\n",
    "        self.data_dict = {}\n",
    "        for name in tqdm(names):\n",
    "            self.data_dict[name] = {}\n",
    "            data = torch.from_numpy(np.load(os.path.join(datapath, f'{name}.npy')))\n",
    "            with open(os.path.join(datapath, f'{name}.pkl'), 'rb') as f:\n",
    "                offsets = pickle.load(f)\n",
    "            # sort out M0 images and functional images\n",
    "            m0imgs, funimgs = [], []\n",
    "            for offset, img in zip(offsets, data):\n",
    "                if int(offset[0]) >= 100:\n",
    "                    img = ifft2c(img)\n",
    "                    m0imgs.append(img)\n",
    "                else:\n",
    "                    funimgs.append(img)\n",
    "            self.data_dict[name]['m0'] = torch.mean(torch.stack(m0imgs), 0, keepdim=True)\n",
    "            self.data_dict[name]['kf'] = torch.stack(funimgs)\n",
    "            self.data_dict[name]['ku'] = {}\n",
    "            self.data_dict[name]['xu'] = {}\n",
    "            # preprocess all the data\n",
    "            self.data_dict[name]['xf'] = ifft2c(self.data_dict[name]['kf'])\n",
    "            for index in range(len(self.data_dict[name]['xf']) - self.nimgs + 1):\n",
    "                xf = self.data_dict[name]['xf'][index:index+self.nimgs].unsqueeze(1).cuda()\n",
    "                self.data_dict[name]['ku'][index] = self.nufft(xf, self.ktrajs).cpu()\n",
    "                ku = self.data_dict[name]['ku'][index].cuda()\n",
    "                self.data_dict[name]['xu'][index] = self.adj(ku*self.dcf, self.ktrajs).squeeze(1).cpu()\n",
    "            del xf, ku\n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for key in self.data_dict.keys():\n",
    "            count += len(self.data_dict[key]['xf']) - self.nimgs + 1\n",
    "        return count\n",
    "    def __getitem__(self, index):\n",
    "        # index corresponds which sample\n",
    "        for key in self.data_dict.keys():\n",
    "            nseq = len(self.data_dict[key]['xf']) - self.nimgs + 1\n",
    "            if index - nseq < 0:\n",
    "                break\n",
    "            index -= nseq\n",
    "        # fetch data\n",
    "        m0 = self.data_dict[key]['m0']\n",
    "        # ragard nimgs as a batch\n",
    "        xf = self.data_dict[key]['xf'][index:index+self.nimgs]\n",
    "        ku = self.data_dict[key]['ku'][index]\n",
    "        xu = self.data_dict[key]['xu'][index]/(self.imsize[0]*self.imsize[1])\n",
    "        return xu, xf, ku, m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:40.593306Z",
     "iopub.status.busy": "2024-09-08T11:56:40.593229Z",
     "iopub.status.idle": "2024-09-08T11:56:40.599354Z",
     "shell.execute_reply": "2024-09-08T11:56:40.599201Z"
    }
   },
   "outputs": [],
   "source": [
    "# define variation network\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, dim_head=64, heads=8):\n",
    "        super().__init__()\n",
    "        self.num_heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.to_q = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.to_k = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.to_v = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.rescale = nn.Parameter(torch.ones(heads, 1, 1))\n",
    "        self.proj = nn.Linear(dim_head * heads, dim, bias=True)\n",
    "        self.pos_emb = nn.Conv2d(dim, dim, 3, 1, 1, bias=False, groups=dim)\n",
    "        self.dim = dim\n",
    "    def forward(self, x_in):\n",
    "        b, c, h, w = x_in.shape\n",
    "        x = x_in.permute(0, 2, 3, 1).reshape(b,h*w,c)\n",
    "        # b, hw, hd\n",
    "        q_inp = self.to_q(x)\n",
    "        k_inp = self.to_k(x)\n",
    "        v_inp = self.to_v(x)\n",
    "        # b, h, hw, d\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.num_heads), (q_inp, k_inp, v_inp))\n",
    "        # b, h, d, hw\n",
    "        q = q.transpose(-2, -1)\n",
    "        k = k.transpose(-2, -1)\n",
    "        v = v.transpose(-2, -1)\n",
    "        q = F.normalize(q, dim=-1, p=2)\n",
    "        k = F.normalize(k, dim=-1, p=2)\n",
    "        # attn: b, h, d, d\n",
    "        attn = (k @ q.transpose(-2, -1))\n",
    "        attn = attn * self.rescale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        # x: b, h, d, hw\n",
    "        x = attn @ v\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.reshape(b, h * w, self.num_heads * self.dim_head)\n",
    "        # out: b, c, h, w\n",
    "        out_c = self.proj(x).view(b, h, w, c).permute(0, 3, 1, 2)\n",
    "        out_p = self.pos_emb(x_in)\n",
    "        out = out_c + out_p\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mult=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim * mult, 1, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dim * mult, dim * mult, 3, 1, 1, bias=False, groups=dim * mult),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dim * mult, dim, 1, 1, bias=False),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, idim, hdim, odim, dim_head=64, heads=8, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.convin = nn.Sequential(nn.Conv2d(idim, hdim, 3, 1, 1, bias=False), nn.GELU())\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(\n",
    "                nn.ModuleList([\n",
    "                    Attention(dim=hdim, dim_head=dim_head, heads=heads),\n",
    "                    FeedForward(dim=hdim)\n",
    "                ])\n",
    "            )\n",
    "        self.convout = nn.Conv2d(hdim, odim, 1, 1, 0)\n",
    "    def forward(self, x, m0):\n",
    "        m0 = view_as_real(m0)\n",
    "        x  = view_as_real(x)\n",
    "        x  = torch.cat([x,m0],1)\n",
    "        x  = self.convin(x)\n",
    "        for (attn, ff) in self.blocks:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        out = self.convout(x)\n",
    "        out = view_as_complex(out)\n",
    "        return out\n",
    "\n",
    "class vn(nn.Module):\n",
    "    def __init__(self, idim, hdim, odim, niter, imsize, ktrajs, parallsize):\n",
    "        super(vn, self).__init__()\n",
    "        self.parallsize = parallsize\n",
    "        self.iters = nn.ModuleList()\n",
    "        for i in range(niter):\n",
    "            self.iters.append(Transformer(idim, hdim, odim))\n",
    "        # contruct nufft object\n",
    "        self.ktrajs = torch.stack(ktrajs).repeat([parallsize,1,1]).cuda()\n",
    "        self.nufft = tkbn.KbNufft(imsize).cuda()\n",
    "        self.adj = tkbn.KbNufftAdjoint(imsize).cuda()\n",
    "        self.dcf = tkbn.calc_density_compensation_function(self.ktrajs, imsize).cuda()\n",
    "    def forward(self, x, ku, m0):\n",
    "        batchsize = x.shape[0]\n",
    "        ind = slice(batchsize*len(self.ktrajs)//self.parallsize)\n",
    "        ku = rearrange(ku, 'b c h w -> (b c) h w')\n",
    "        for iter, layer in enumerate(self.iters):\n",
    "            x = rearrange(x, 'b c h w -> (b c) 1 h w')\n",
    "            kres = self.nufft(x, self.ktrajs[ind]) - ku\n",
    "            xdc = self.adj(kres*self.dcf[ind], self.ktrajs[ind])\n",
    "            xdc = rearrange(xdc, '(b c) 1 h w -> b c h w', b = batchsize)\n",
    "            x = rearrange(x, '(b c) 1 h w -> b c h w', b = batchsize)\n",
    "            xdc = xdc / abs(xdc).max()\n",
    "            x = x + layer(x,m0) - xdc\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:40.600275Z",
     "iopub.status.busy": "2024-09-08T11:56:40.600182Z",
     "iopub.status.idle": "2024-09-08T11:56:40.601753Z",
     "shell.execute_reply": "2024-09-08T11:56:40.601604Z"
    }
   },
   "outputs": [],
   "source": [
    "# define learning rate scheduler\n",
    "\n",
    "class PolyScheduler(LambdaLR):\n",
    "    def __init__(self, optimizer, t_total, exponent=0.9, last_epoch=-1):\n",
    "        self.t_total = t_total\n",
    "        self.exponent = exponent\n",
    "        super(PolyScheduler, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        return (1 - step / self.t_total)**self.exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T11:56:40.602569Z",
     "iopub.status.busy": "2024-09-08T11:56:40.602508Z",
     "iopub.status.idle": "2024-09-09T06:44:50.165042Z",
     "shell.execute_reply": "2024-09-09T06:44:50.164744Z"
    }
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "\n",
    "batchsize = 8\n",
    "trainset = dataset('data/processed/trains', ktrajs=ktrajs, imsize=imsize, nimgs=nimgs)\n",
    "trainloader = DataLoader(trainset, batchsize, shuffle=True, drop_last=True)\n",
    "\n",
    "# take a snapshot of xu, xf, and m0\n",
    "xu, xf, ku, m0 = trainset.__getitem__(0)\n",
    "print(xu.shape, xf.shape, ku.shape, m0.shape)\n",
    "for i in range(nimgs):\n",
    "    plt.subplot(2, nimgs, i+1)\n",
    "    plt.imshow(abs(xu)[i].cpu().numpy(), cmap='gray')\n",
    "    plt.subplot(2, nimgs, nimgs+i+1)\n",
    "    plt.imshow(abs(xf)[i].cpu().numpy(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# hyper-parameters\n",
    "lr, weight_decay, epochs = 1e-4, 1e-4, 60\n",
    "\n",
    "net = vn(idim=2*(1+nimgs), hdim=16, odim=2*nimgs, niter=6, ktrajs=ktrajs, imsize=imsize, parallsize=batchsize).cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = PolyScheduler(optimizer, t_total=epochs)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "iter = 0\n",
    "writer = SummaryWriter()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(epochs):\n",
    "    for xu, xf, ku, m0 in trainloader:\n",
    "        xu, xf, ku, m0 = xu.cuda(), xf.cuda(), ku.cuda(), m0.cuda()\n",
    "        xr = net(xu, ku, m0)\n",
    "        loss = criterion(xr, xf)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(),1.0)\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        writer.add_scalar('Loss/train', loss.item(), iter)\n",
    "        iter = iter + 1\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(net.state_dict(), 'variables/motr_spiral/motr.pth')\n",
    "\n",
    "# take a snapshot of xr and xf\n",
    "for i in range(nimgs):\n",
    "    plt.subplot(2, nimgs, i+1)\n",
    "    plt.imshow(abs(xr)[0][i].detach().cpu().numpy())\n",
    "    plt.subplot(2, nimgs, nimgs+i+1)\n",
    "    plt.imshow(abs(xf)[0][i].detach().cpu().numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
